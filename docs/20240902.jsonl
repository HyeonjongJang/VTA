{"id": null, "metadata": {"source": "01_intro.pdf"}, "page_content": "Source : 01_intro.pdf\n\nAI504: Programming for Artificial Intelligence\n\nWeek 1: Introduction\n\nEdward Choi\nGrad School of AI\nedwardchoi@kaist.ac.kr\n\n\fWhat is AI?\n\nArtificial Intelligence\n\nMake machines/computers mimic human intelligence\nConcept as old as the computer (Chess program by Alan Turing)\n\n\fWhat is Machine Learning?\n\nArtificial Intelligence\n\nMachine Learning\n\nUse statistical methods to teach machines to learn from\ndata to be good at a specific task (Spam filtering)\n\n\fWhat is Deep Learning?\n\nArtificial Intelligence\n\nMachine Learning\n\nDeep Learning\n\nTrain machines to be good at complex tasks \nbased on neural networks and massive data\n\n\fWhy Deep Learning?\n\nState-of-the-art performance\n\nImageNet Classification Error\n\nSurvey of neural networks in autonomous driving, Gustav von Zitzewitz,\nAdvanced Seminar SS 2017: Survey of Neural Networks in Autonomous Driving\n\n\fWhy Deep Learning?\n\nLess feature enginnering\n\nEyes? Color?\nNose? Fur?\nEars? Tongue?\n\nDog\n\nCat\n\nInput\n\nFeature Extraction\n\nClassification\n\nClassical machine learning process\n\n\fWhy Deep Learning?\n\nLess feature engineering\n\nDog\n\nCat\n\nInput\n\nFeature Extraction + Classification\n\nDeep learning process\n\n\fHow is this Possible?\n\nLarge data\n\n\u25cf Social network services\n\n\u25cb Youtube, Instagram, Twitter\n\n\u25cf Collective intelligence\n\n\u25cb Wikipedia\n\u25cf Mass media\n\n\u25cb News articls\n\nImageNet\n\n\fHow is this Possible?\n\nLarge data + Powerful machines\n\n\f(Almost) Infinite Compute + (Almost) Infinite Data\n\nProbably > 10k A100\u2019s\n\nProbably the entire Internet\n\n2023\ub144\ub3c4 \uc218\ub2a5\uc5b8\uc5b4\u201d\ud654\ubc95\uacfc \uc791\ubb38\u201d\n\n> 1T Parameters\n> $1 Billion for development\n\n\fGPT-4o, Multi-modal LLM\n\u2022 Input: Video/Audio/Text,    Output: Text/Audio\n\n\u2022 Tens (maybe hundreds) of Transformer layers\n\n\fDALL-E 3, Image Generation\n\n\u2022 Conditional text-to-image generator\n\u2022 Diffusion + Transformer\n\n\fSora, Video Generation\n\u2022 Conditional text-to-video generator\n\n\u2022 Transformer + Diffusion", "type": "Document"}
{"id": null, "metadata": {"source": "01_intro.pdf"}, "page_content": "Source : 01_intro.pdf\n\n\u2022 Tens (maybe hundreds) of Transformer layers\n\n\fDALL-E 3, Image Generation\n\n\u2022 Conditional text-to-image generator\n\u2022 Diffusion + Transformer\n\n\fSora, Video Generation\n\u2022 Conditional text-to-video generator\n\n\u2022 Transformer + Diffusion\n\nPrompt: A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black \nleather jacket, a long red dress, and black boots, and carries a black purse. She wears sunglasses and red lipstick. She walks \nconfidently and casually. The street is damp and reflective, creating a mirror effect of the colorful lights. Many pedestrians walk about.\n\n\fUdio, Audio Generation\n\u2022 Conditional text-to-music generation\n\n\u2022 Probably Transformer + Diffusion\n\nDune, the Broadway Musical\n\n\fAlphaFold3\n\n\u2022 DeepMind\u2019s biomoleculear interaction prediction model\n\n\u2013 Using Pairformer blocks + Diffusion blocks\n\n\u2022 Special self-attention for graphs in 3D\n\n\fTransformer Architecture\n\nhttp://jalammar.github.io/illustrated-transformer/\n\n\fGoal\n\n\u2022 Learn to build deep learning models.\n\n\u2013 So that you can replicate papers\n\u2013 So that you can realize your ideas\n\u2013 So that you can conduct AI research\n\n\u2022 Feel free to use tools\n\n\u2013 Copilot, ChatGPT, Claude, etc.\n\n\u2022 This course teaches only the very basics.\n\n\u2013 Practice makes perfect!\n\n\fStructure\n\n\u2022 Schedule\n\n\u2013 Lecture on Tuesday\n\n\u2022 Conducted by the lecturer\n\n\u2013 Practice on Thursday\n\u2022 Conducted by the TA\n\n\u2013 All material will be uploaded on KLMS\n\n\u2022 Evaluation\n\n\u2013 Pass or Fail\n\n\u2022 You must pass all 3 projects\n\n\u2013 No attendance check\n\u2022 Up to you to attend\n\n\fWeekly Plan\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n13.\n14.\n15.\n16.", "type": "Document"}
{"id": null, "metadata": {"source": "01_intro.pdf"}, "page_content": "Source : 01_intro.pdf\n\n\u2013 All material will be uploaded on KLMS\n\n\u2022 Evaluation\n\n\u2013 Pass or Fail\n\n\u2022 You must pass all 3 projects\n\n\u2013 No attendance check\n\u2022 Up to you to attend\n\n\fWeekly Plan\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n13.\n14.\n15.\n16.\n\nIntro + Numpy\nBasic Machine Learning + Scikit-learn\nPyTorch Intro + Logistic Regression + Multi-layer Perceptron\nAutoencoders (& Denoising Autoencoders)\nVariational Autoencoders\nGenerative Adversarial Networks\nConvolutional Neural Networks\nProject 1: Image Classification\nWord2Vec + Subword Encoding\nRecurrent Neural Networks & Sequence-to-Sequence\nTransformers\nBERT & GPT\nProject 2: Language Model\nDeep Diffusion Probabilistic Model\nImage-Text Multimodal Learning\nProject 3: Visual Language Model\n\nExtra: Neural ODE, Graph Neural Networks \u00e8 Will share video only\n\n\fExpectation\n\n\u2022\n\nLecture attendance: Up to you\n\u2013 477 people enrolled in this course\n\u2013 Last year material: https://mp2893.com/course.html\n\n\u2022 Projects\nImage classification using CNN\n1.\nLanguage model using Transformer\n2.\nVisual Large Language Model (Visual LLM)\n3.\n\u2013 All projects are given 24hr to submit your code\n\n\u2022 Expected to take approximately 1hr (training will take about 5min on Colab)\n\u2022 Designed to evaluate only model programming, not model performance\n\n\u2013 Individual effort\n\n\u2022 Plagiarism, if caught, will lead to serious consequences\n\u2022 Using LLMs are okay\n\n\fTeaching Team\n\n\u2022\n\nLecturer\n\u2013 Edward Choi\n\n\u2022 edwardchoi@kaist.ac.kr\n\u2022 https://mp2893.com\n\n\u2022 TA\n\n\u2013 Sunjun Kweon\n\n\u2022 sean0042@kaist.ac.kr\n\n\u2022 AI\n\n\u2013 https://chatgpt.com/g/g-8WEMSCAD4-ai504-teaching-assistant-gpt\n\u2013 AI will handle all your questions outside the class\n\n\u2022 No Q&A using KLMS\n\n\u2013 Come to the class if you want to personally ask questions\n\n\fEdward Choi, \ucd5c\uc724\uc7ac\n\n\u2022 Education\n\n\u2013 Ph.D. (computer science), Georgia Tech, 2014-2018\n\n\u2022 Thesis: Interpretable deep learning for longitudinal electronic health \n\nrecords\n\n\u2022 Professional Experience\n\n\u2013 ETRI (2010-2014)\n\u2013 Sutter Health (2015, 2016)\n\u2013 DeepMind & Google (2017)\n\u2013 Google Brain & Google Health (2018-2020)\n\n\u2022 Research Area", "type": "Document"}
{"id": null, "metadata": {"source": "01_intro.pdf"}, "page_content": "Source : 01_intro.pdf\n\n\u2022 Thesis: Interpretable deep learning for longitudinal electronic health \n\nrecords\n\n\u2022 Professional Experience\n\n\u2013 ETRI (2010-2014)\n\u2013 Sutter Health (2015, 2016)\n\u2013 DeepMind & Google (2017)\n\u2013 Google Brain & Google Health (2018-2020)\n\n\u2022 Research Area\n\n\u2013 Machine Learning, Healthcare, NLP, Multi-modal\n\n22\n\n\fResearch Experiment\n\n\u2022 Can LLMs handle course-related Q&A as effectively as human TAs?\n\n\u2022 We will collect the following:\n\n\u2013 Student profiles\n\n\u2022 Age, gender, home department, coding skills, ML knowledge, etc.\n\n\u2013 Conversation logs\n\n\u2022 We are developing a LangChain-based system\n\n\u2013 Satisfaction surveys\n\n\u2022 3-4 times over the semester\n\n\u2013 Interviews\n\n\u2022 Several students who actively used the LLM\n\n\fFirst Assignment\n\n\u2022 Install Anaconda\n\n\u2013 Python package for data science\n\u2013 Includes Jupyter, Numpy, Scikit-Learn, TensorFlow, PyTorch\n\u2013 https://www.anaconda.com/products/individual\n\n\u2022 All practice sessions will be conducted with Google Colab\n\n\u2013 Python Notebook on the web\n\u2013 Can train models using Google\u2019s GPU/TPU\n\u2013 Session-based (why you need Anaconda)\n\n\fQuestions?\n\n\fAI504: Programming for Artificial Intelligence\n\nWeek 1: Introduction\n\nEdward Choi\nGrad School of AI\nedwardchoi@kaist.ac.kr", "type": "Document"}
